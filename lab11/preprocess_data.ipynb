{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python369jvsc74a57bd04cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462",
   "display_name": "Python 3.6.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_filepath =\"./data/movie_lines.txt\"\n",
    "conv_filepath = \"./data/movie_conversations.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\nL1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\nL985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\nL984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\nL925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\nL924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\nL872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\nL871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\nL870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I'm kidding.  You know how sometimes you just become this \"persona\"?  And you don't know how to quit?\nL869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?\n"
     ]
    }
   ],
   "source": [
    "# visualizing some lines\n",
    "with open(lines_filepath,'r',encoding='iso-8859-1') as file:\n",
    "    lines = file.readlines()\n",
    "for line in lines[:10]:\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits each line of the file into a dictionary of fields(lineID,characterID,movieID,character,text)\n",
    "line_fields = [\"lineID\",\"characterID\",\"movieID\",\"character\",\"text\"]\n",
    "lines = {}\n",
    "\n",
    "with open(lines_filepath, 'r', encoding='iso-8859-1') as f:\n",
    "    for line in f:\n",
    "        values = line.split(\" +++$+++ \")\n",
    "        # Extract fields\n",
    "        lineObj = {}\n",
    "        for i, field in enumerate(line_fields):\n",
    "            lineObj[field] = values[i]\n",
    "        lines[lineObj['lineID']] = lineObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Grouping fields of lines from the above loaded lines into conversation based on \"movie_conversations.txt\"\n",
    "\n",
    "conv_fields = [\"character1ID\", \"character2ID\", \"movieID\", \"utteranceIDs\"]\n",
    "conversations = []\n",
    "\n",
    "with open(conv_filepath, 'r', encoding='iso-8859-1') as f:\n",
    "    for line in f:\n",
    "        values = line.split(\" +++$+++ \")\n",
    "        # Extract fields\n",
    "        convObj = {}\n",
    "        for i, field in enumerate(conv_fields):\n",
    "            convObj[field] = values[i]\n",
    "        lineIds = eval(convObj[\"utteranceIDs\"])\n",
    "        # Reassemble lines\n",
    "        convObj[\"lines\"] = []\n",
    "        for lineId in lineIds:\n",
    "            convObj[\"lines\"].append(lines[lineId])\n",
    "        conversations.append(convObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extracts pairs of sentences from conversations\n",
    "qa_pairs = []\n",
    "for conversation in conversations:\n",
    "    # Iterate over all the lines of the conversation\n",
    "    for i in range(len(conversation[\"lines\"]) - 1):  # We ignore the last line (no answer for it)\n",
    "        inputLine = conversation[\"lines\"][i][\"text\"].strip()\n",
    "        targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n",
    "        # Filter wrong samples (if one of the lists is empty)\n",
    "        if inputLine and targetLine:\n",
    "            qa_pairs.append([inputLine, targetLine])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nWriting newly formatted file...\n"
     ]
    }
   ],
   "source": [
    "# Define path to new file\n",
    "datafile = \"formatted_movie_lines.txt\"\n",
    "\n",
    "delimiter = '\\t'\n",
    "# Unescape the delimiter\n",
    "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
    "\n",
    "# Writing the conversational pairs into new csv file\n",
    "print(\"\\nWriting newly formatted file...\")\n",
    "with open(datafile, 'w', encoding='utf-8') as outputfile:\n",
    "    writer = csv.writer(outputfile, delimiter=delimiter)\n",
    "    for pair in qa_pairs:\n",
    "        writer.writerow(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "b\"Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\tWell, I thought we'd start with pronunciation, if that's okay with you.\"\nb\"Well, I thought we'd start with pronunciation, if that's okay with you.\\tNot the hacking and gagging and spitting part.  Please.\"\nb\"Not the hacking and gagging and spitting part.  Please.\\tOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?\"\nb\"You're asking me out.  That's so cute. What's your name again?\\tForget it.\"\nb\"No, no, it's my fault -- we didn't have a proper introduction ---\\tCameron.\"\nb\"Cameron.\\tThe thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\"\nb\"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\tSeems like she could get a date easy enough...\"\nb'Why?\\tUnsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.'\nb\"Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\tThat's a shame.\"\nb'Gosh, if only we could find Kat a boyfriend...\\tLet me see what I can do.'\n"
     ]
    }
   ],
   "source": [
    "# visualizing some lines\n",
    "with open(datafile,'rb') as file:\n",
    "    lines = file.readlines()\n",
    "for line in lines[:10]:\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}