{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTML Final 2021\n",
    "\n",
    "In this exam, we'll have some practical exercises using RNNs and some short answer questions regarding the Transformer/attention\n",
    "and reinforcement learning.\n",
    "\n",
    "Consider the AGNews text classification dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Label frequencies: {3: 30000, 4: 30000, 2: 30000, 1: 30000}\nA few token frequencies: [('to', 106167), ('of', 71310), ('in', 64953), ('on', 47273), ('for', 36960)]\nLabel meanings: 1: World news, 2: Sports news, 3: Business news, 4: Sci/Tech news\n"
     ]
    }
   ],
   "source": [
    "from torchtext.datasets import AG_NEWS\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "\n",
    "#train_iter = pd.read_csv(\"./data/.data/train.csv\")\n",
    "#train_iter['summary'] = train_iter['Title'] + ' ' + train_iter['Description']\n",
    "train_iter = AG_NEWS(root='.data',split='train')\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "counter = Counter()\n",
    "\n",
    "\n",
    "def clean(line):\n",
    "    line = line.replace('\\\\', ' ')\n",
    "    line = re.sub('(\\s+)(a|an|and|the)(\\s+)', '\\1\\3', line)\n",
    "    line = re.sub('[%s]' % re.escape(string.punctuation), '', line)\n",
    "\n",
    "    return line\n",
    "\n",
    "labels = {}\n",
    "for (label, line) in train_iter:\n",
    "    if label in labels:\n",
    "        labels[label] += 1\n",
    "    else:\n",
    "        labels[label] = 1\n",
    "    counter.update(tokenizer(clean(line)))\n",
    "\n",
    "vocab = Vocab(counter, min_freq=0, max_size=1000)\n",
    "\n",
    "print('Label frequencies:', labels)\n",
    "print('A few token frequencies:', vocab.freqs.most_common(5))\n",
    "print('Label meanings: 1: World news, 2: Sports news, 3: Business news, 4: Sci/Tech news')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we can get a sequence of tokens for a sentence with the cleaner, tokenizer, and vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[3914, 96, 8, 291, 0, 11, 45, 7438, 1990, 3, 1057]"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "[vocab[token] for token in tokenizer(clean('Bangkok, or The Big Mango, is one of the great cities of Asia'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make pipelines for processing a news story and a label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: [vocab[token] for token in tokenizer(clean(x))]\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to create dataloaders for the training and test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, length_list = [], [], []\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        length_list.append(processed_text.shape[0])\n",
    "        text_list.append(processed_text)\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    text_list = pad_sequence(text_list, padding_value=0)\n",
    "    length_list = torch.tensor(length_list, dtype=torch.int64)\n",
    "    return label_list.to(device), text_list.to(device), length_list.to(device)\n",
    "\n",
    "train_iter = AG_NEWS(split='train')\n",
    "train_dataset = list(train_iter)\n",
    "test_iter = AG_NEWS(split='test')\n",
    "test_dataset = list(test_iter)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to get a batch from one of these dataloaders. The first entry is a 1D tensor of labels for the batch\n",
    "(8 values between 0 and 3), then a 2D tensor representing the stories with dimension T x B (number of tokens x batch size). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(0, (tensor([3, 1, 0, 0, 0, 2, 3, 1], device='cuda:0'), tensor([[   491,    136,   1145,  59356,   5454,   3052,   1388,   9830],\n        [  3516,    895,    272,   1124,   1435,      2,   1352, 231994],\n        [  4962,   2025,    424,   5895,   1637,    251,   3800,    242],\n        [ 50357,   2308,     16,  54052,   1083,   9010,    220,      6],\n        [   491,     23,  49994,  13942,    846,      6,    457,     22],\n        [    16,   5530,     19,     39,     72,  18237,      6,   2812],\n        [213605,  41516,     19,  12709,     72,     60,  96872,   9830],\n        [    65,   7562,    744,  39289,   1486,    177,     19, 140479],\n        [   201,  40739,    424,     25,     56,     17,     19, 227501],\n        [  7628,    540,  72416,  29607,   2217,   3052, 165581,    634],\n        [ 50357,  39511,  71440,    843,   1435,     84,    363,      4],\n        [ 29398,  11110,   1145,     72,   8047,   1913,    162,   1191],\n        [   129,  12040,    272,     72,  57174,     24,  18318,   9286],\n        [ 93032,   2744,     13,   1528,    532,    251,   1388,   2512],\n        [     8,    386,     42,      3,      6,   9010,     53,     54],\n        [  1232,     38,  46270,  12709,    122,    222,     11,  86764],\n        [    77,      9,    306, 174853,     15,     81,  64921,   1106],\n        [    24,     11,    169,  25762,     56,      6,    317,  62271],\n        [    29,   3682,   1748,   1399,  12892,  18237,  11578,   1417],\n        [   841,    166,     23,  59356,  13762,     60,     77,   5311],\n        [179826,     11,   6132,     73,  10927,      4,  15087,   1309],\n        [    25,    539,  69627,   6815,   6858,    742,      4,      0],\n        [ 14337,      2,     35,   7726,   8903,   1229,    131,      0],\n        [ 46362,    207,   1015,  24279,     12,   2211,   7894,      0],\n        [244690,    540,   1304,    378,     34,    149,      3,      0],\n        [     0,     94,  32492, 192727,    840,  15387, 107799,      0],\n        [     0,     92,      3,    106,      2,   4192,  11001,      0],\n        [     0,    136,     23,     86,   4128,     78,      6,      0],\n        [     0,    895,   1779,   3912,     23,  20429,     67,      0],\n        [     0,   1020,      0,     13,   5288,  12909,  96871,      0],\n        [     0,   7984,      0,    213,    153,    751,     60,      0],\n        [     0,    866,      0, 135719,  88659, 128079,      4,      0],\n        [     0, 130247,      0,     26,     21,   3159,  27837,      0],\n        [     0,  41516,      0, 225089,    618,   2891,      0,      0],\n        [     0,   6464,      0,      4,      0,    996,      0,      0],\n        [     0,    801,      0,   1555,      0, 227468,      0,      0],\n        [     0,  11110,      0,     18,      0,      0,      0,      0],\n        [     0,     18,      0, 253998,      0,      0,      0,      0],\n        [     0,  41516,      0,   6391,      0,      0,      0,      0],\n        [     0,  14744,      0, 152416,      0,      0,      0,      0],\n        [     0,    609,      0,   1077,      0,      0,      0,      0],\n        [     0,      0,      0,  10437,      0,      0,      0,      0],\n        [     0,      0,      0,    843,      0,      0,      0,      0]],\n       device='cuda:0'), tensor([25, 41, 29, 43, 34, 36, 33, 21], device='cuda:0')))\n"
     ]
    }
   ],
   "source": [
    "batch = next(enumerate(train_dataloader))\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1, 10 points\n",
    "\n",
    "The vocabulary currently is too large for a simple one-hot embedding. Let's reduce the vocabulary size\n",
    "so that we can use one-hot. First, add a step that removes tokens from a list of \"stop words\" to the `text_pipeline` function.\n",
    "You probably want to remove punctuation ('.', ',', '-', etc.) and articles (\"a\", \"the\").\n",
    "\n",
    "Once you've removed stop words, modify the vocabulary to include only the most frequent 1000 tokens (including 0 for an unknown/infrequent word).\n",
    "\n",
    "Write your revised code in the cell below and output the 999 top words with their frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place code for Question 1 here\n",
    "def clean(line):\n",
    "    line = line.replace('\\\\', ' ')\n",
    "    #Add for question one\n",
    "    line = re.sub('(\\s+)(a|an|and|the)(\\s+)', '\\1\\3', line)\n",
    "    line = re.sub('[%s]' % re.escape(string.punctuation), '', line)\n",
    "    return line\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2, 30 points\n",
    "\n",
    "Next, let's build a simple RNN for classification of the AGNews dataset. Use a one-hot embedding of the vocabulary\n",
    "entries and the basic RNN from Lab 10. Use the lengths tensor (the third element in the batch returned by the dataloaders)\n",
    "to determine which output to apply the loss to.\n",
    "\n",
    "Place your training code below, and plot the training and test accuracy as a\n",
    "function of epoch. Finally, output a confusion matrix for the test set.\n",
    "\n",
    "*Do not spend a lot of time on the training! A few minutes is enough. The point is to show that the model is\n",
    "learning, not to get the best possible performance.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place code for Question 2 here\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "n_hidden = 128 \n",
    "n_tag = 4\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)\n",
    "#train\n",
    "net = RNN(vocab_size,emsize,num_class).to(device)\n",
    "criterion = nn.NLLLoss()\n",
    "opt = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    net.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        opt.zero_grad()\n",
    "        predited_label = net(text, offsets)\n",
    "        loss = criterion(predited_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        opt.step()\n",
    "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    net.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predited_label = net(text, offsets)\n",
    "            loss = criterion(predited_label, label)\n",
    "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "forward() takes 2 positional arguments but 3 were given",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-6cc7538ef1ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0maccu_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtotal_accu\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtotal_accu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0maccu_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-104-9686dc2f9267>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mpredited_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredited_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-103-33ffbf708fbf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text, offsets)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10 # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 64 # batch size for training\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "      scheduler.step()\n",
    "    else:\n",
    "       total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3, 10 points\n",
    "\n",
    "Next, replace the SRNN from Question 2 with a single-layer LSTM. Give the same output (training and testing accuracy as a function of epoch, as well as confusion\n",
    "matrix for the test set). Comment on the differences you observe between the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place code for Question 3 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4, 10 points\n",
    "\n",
    "Explain how you could use the Transformer model to perform the same task you explored in Questions 2 and 3.\n",
    "How would attention be useful for this text classification task? Give a precise and detailed answer. Be sure to discuss what\n",
    "parts of the original Transformer you would use and what you would have to remove."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "Transformer model can use a sequence of text as a input of model. This model can do as parallelization of sequence. For this task, there are many tag or many word in sentence. self-Attention machanism could be help for AgNews dataset which it try to looks at an input sequence and decides at each step which other parts of the sequence are important. To modify code for self-Attention, we need to separate part into docoder and encoder,and add more linear layer as a V, Q, K (multihead attention) after that we use same softmax function for output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5, 10 points\n",
    "\n",
    "In Lab 13, you implemented a DQN model for tic-tac-toe. You method learned to play against a fairly dumb `expert_action` opponent, however.  Also,\n",
    "DQN has proven to be less stable than other methods such as Double DQN, also discussed in Lab 13.\n",
    "\n",
    "Explain below how you would apply double DQN and self-play to improve your tic-tac-toe agent.\n",
    "Provide pseudocode for the algorithm below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "Double DQN is part of RL model which contain 2 neural network model.First, model learn during the experience play as same as DQN. Second, copy last episode of the first model to compare for Q-value. If values of the second model are lower that the main model, we use second model to attain Q-value. Sometime DQN overestimate the reward so double DQN decoupling the actions selection from the action evaluation. To apply double DQN for tic-tac-toe, the input is as same as DQN but we need to create 2 neural network. First neural network will decides which one is the best next action and then second network evaluates this action to know Q-value.\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "#Pseudo code\n",
    "def select_greedy_actions(states: torch.Tensor, q_network: nn.Module) -> torch.Tensor:\n",
    "    \n",
    "    _, actions = q_network(states).max(dim=1, keepdim=True)\n",
    "    return actions\n",
    "\n",
    "\n",
    "def evaluate_selected_actions(states: torch.Tensor,\n",
    "                              actions: torch.Tensor,\n",
    "                              rewards: torch.Tensor,\n",
    "                              dones: torch.Tensor,\n",
    "                              gamma: float,\n",
    "                              q_network: nn.Module) -> torch.Tensor:\n",
    "    next_q_values = q_network(states).gather(dim=1, index=actions)        \n",
    "    q_values = rewards + (gamma * next_q_values * (1 - dones))\n",
    "    return q_values\n",
    "def double_q_learning_update(states: torch.Tensor,\n",
    "                             rewards: torch.Tensor,\n",
    "                             dones: torch.Tensor,\n",
    "                             gamma: float,\n",
    "                             q_network_1: nn.Module,\n",
    "                             q_network_2: nn.Module) -> torch.Tensor:\n",
    "  \n",
    "    actions = select_greedy_actions(states, q_network_1)\n",
    "    q_values = evaluate_selected_actions(states, actions, rewards, dones, gamma, q_network_2)\n",
    "    return q_values"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "#Pseudo code\n",
    "\n",
    "q_network1 is first neural network\n",
    "\n",
    "q_network2 is secone neural network\n",
    "\n",
    "\n",
    "\n",
    "Select_greedy_actions(state,q_network)\n",
    "\n",
    "        Selection action for q_network\n",
    "\n",
    "evaluate_action(state,action,reward,done,q_network)\n",
    "\n",
    "        findding a next q value from q_network\n",
    "                \n",
    "        evaluate q value\n",
    "\n",
    "DDQN_update(state,reward,done,q_network1,q_network2)\n",
    "\n",
    "        selection from Select_greedy_actions by using state and q q_network1\n",
    "\n",
    "        evaluate action from evaluate_action which using q_network2 which return q value from seconde neural network\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6, 30 points\n",
    "\n",
    "Based on your existing DQN implementation, implement the double DQN and self-play training method\n",
    "you just described. After some training (don't spend too much time on training -- again, we just want to see that the model can\n",
    "learn), show the result you playing a game against your learned agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for training and playing goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}